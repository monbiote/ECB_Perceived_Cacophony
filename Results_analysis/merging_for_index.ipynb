{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download trained and monetary policy statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles=pd.read_csv('/Users/ruimaciel/Desktop/Local_ECB_Cacophony_Master_Thesis/df_final_with_bert_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monetary_policy=pd.read_excel('/Users/ruimaciel/Desktop/Local_ECB_Cacophony_Master_Thesis/ecb_monetary_policy_decisions_classified.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monetary_policy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Monetary policy Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all text is in the same case and spaces are stripped\n",
    "df_monetary_policy['Classification Joaquin'] = df_monetary_policy['Classification Joaquin'].str.lower().str.strip()\n",
    "df_monetary_policy['Classification Ed'] = df_monetary_policy['Classification Ed'].str.lower().str.strip()\n",
    "df_monetary_policy['Classification Rui'] = df_monetary_policy['Classification Rui'].str.lower().str.strip()\n",
    "\n",
    "# Define the mapping\n",
    "sentiment_mapping = {\n",
    "    'dovish': -1,\n",
    "    'neutral': 0,\n",
    "    'hawkish': 1\n",
    "}\n",
    "\n",
    "# Apply the mapping to each column\n",
    "df_monetary_policy['Classification Joaquin'] = df_monetary_policy['Classification Joaquin'].map(sentiment_mapping)\n",
    "df_monetary_policy['Classification Ed'] = df_monetary_policy['Classification Ed'].map(sentiment_mapping)\n",
    "df_monetary_policy['Classification Rui'] = df_monetary_policy['Classification Rui'].map(sentiment_mapping)\n",
    "\n",
    "# Check the results\n",
    "print(df_monetary_policy[['Classification Joaquin', 'Classification Ed', 'Classification Rui']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of the three columns\n",
    "df_monetary_policy['Average Classification'] = df_monetary_policy[['Classification Joaquin', 'Classification Ed', 'Classification Rui']].mean(axis=1)\n",
    "\n",
    "# Check the results\n",
    "print(df_monetary_policy[['Classification Joaquin', 'Classification Ed', 'Classification Rui', 'Average Classification']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format if not already\n",
    "df_monetary_policy['Date'] = pd.to_datetime(df_monetary_policy['Date'])\n",
    "\n",
    "# Now strip off the time\n",
    "df_monetary_policy['Date'] = df_monetary_policy['Date'].dt.date\n",
    "\n",
    "# Check the result\n",
    "df_monetary_policy['Date'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Name_of_Speaker\" and fill it with \"ECB_MONETARY_STATEMENT\"\n",
    "df_monetary_policy['Name_of_Speaker'] = 'ECB_MONETARY_STATEMENT'\n",
    "\n",
    "# Drop the specified columns\n",
    "df_monetary_policy = df_monetary_policy.drop(columns=['Title', 'Link', 'Classification Joaquin', 'Classification Ed', 'Classification Rui'])\n",
    "\n",
    "# Rename columns\n",
    "df_monetary_policy = df_monetary_policy.rename(columns={'Average Classification': 'Sentiment', 'Article': 'Statement'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monetary_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Open_AI and Bert_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the specified columns\n",
    "df_articles = df_articles[['Date', 'Manual.summary', 'Name_of_Speaker', 'OpenAI_Score', 'bert_predictions_everything']]\n",
    "\n",
    "# Transform Date to keep only the date part\n",
    "df_articles['Date'] = pd.to_datetime(df_articles['Date']).dt.date\n",
    "\n",
    "# Rename columns\n",
    "df_articles = df_articles.rename(columns={'Manual.summary': 'Statement'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary\n",
    "label_mapping = {'LABEL_2': 0, 'LABEL_1': 1, 'LABEL_0': -1}\n",
    "\n",
    "# Replace the labels in the DataFrame\n",
    "df_articles['bert_predictions_everything'] = df_articles['bert_predictions_everything'].replace(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where OpenAI_Score is not NaN\n",
    "filtered_df = df_articles.dropna(subset=['OpenAI_Score'])\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values from each row\n",
    "for index, row in filtered_df.iterrows():\n",
    "    print(f\"Row {index}: OpenAI_Score = {row['OpenAI_Score']}, bert_predictions_everything = {row['bert_predictions_everything']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Error' with NaN and convert to float\n",
    "filtered_df.replace('Error', np.nan, inplace=True)\n",
    "filtered_df['OpenAI_Score'] = filtered_df['OpenAI_Score'].astype(float)\n",
    "filtered_df['bert_predictions_everything'] = filtered_df['bert_predictions_everything'].astype(float)\n",
    "\n",
    "# Compare columns and count matches\n",
    "matches = (filtered_df['OpenAI_Score'] == filtered_df['bert_predictions_everything']).sum()\n",
    "\n",
    "# Display the count of matches\n",
    "print(f\"Number of matches: {matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'OpenAI_Score' and count the occurrences of each 'bert_predictions_everything' value\n",
    "bert_counts = filtered_df.groupby(['OpenAI_Score', 'bert_predictions_everything']).size().unstack(fill_value=0)\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of bert_predictions_everything values for each OpenAI_Score:\")\n",
    "print(bert_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.DataFrame(bert_counts, index=[-1.0, 0.0, 1.0])\n",
    "confusion_matrix.columns = pd.MultiIndex.from_tuples([(\"bert_predictions_everything\", col) for col in confusion_matrix.columns])\n",
    "\n",
    "# Calculating precision and recall\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1_scores = {}\n",
    "\n",
    "for label in confusion_matrix.index:\n",
    "    tp = confusion_matrix.loc[label, (\"bert_predictions_everything\", label)]\n",
    "    fp = confusion_matrix[(\"bert_predictions_everything\", label)].sum() - tp\n",
    "    fn = confusion_matrix.loc[label].sum() - tp\n",
    "    precision[label] = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    recall[label] = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    f1_scores[label] = 2 * (precision[label] * recall[label]) / (precision[label] + recall[label]) if (precision[label] + recall[label]) != 0 else 0\n",
    "\n",
    "# Display the results\n",
    "print(\"Precision per class:\", precision)\n",
    "print(\"Recall per class:\", recall)\n",
    "print(\"F1 Score per class:\", f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Articles for creating the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count 'Error' in 'bert_predictions_everything'\n",
    "error_count = df_articles['bert_predictions_everything'].value_counts().get('Error', 0)\n",
    "print(\"Count of 'Error' in bert_predictions_everything:\", error_count)\n",
    "\n",
    "error_count = df_articles['OpenAI_Score'].value_counts().get('Error', 0)\n",
    "print(\"Count of 'Error' in OpenAI_Score:\", error_count)\n",
    "\n",
    "# Step 2: Remove rows where 'bert_predictions_everything' is 'Error'\n",
    "print(df_articles.shape[0])\n",
    "df_articles = df_articles[df_articles['bert_predictions_everything'] != 'Error']\n",
    "print(df_articles.shape[0])\n",
    "df_articles = df_articles[df_articles['OpenAI_Score'] != 'Error']\n",
    "print(df_articles.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles['OpenAI_Score'] = df_articles['OpenAI_Score'].astype(float)\n",
    "df_articles['bert_predictions_everything'] = df_articles['bert_predictions_everything'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'Sentiment' column\n",
    "df_articles['Sentiment'] = df_articles['OpenAI_Score'].combine_first(df_articles['bert_predictions_everything'])\n",
    "\n",
    "# Calculate and print the unique counts and the amount of each in the 'Sentiment' column\n",
    "unique_values_counts = df_articles['Sentiment'].value_counts()\n",
    "print(\"Unique values and their counts in the 'Sentiment' column:\")\n",
    "print(unique_values_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles.drop(columns=['OpenAI_Score', 'bert_predictions_everything'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the information out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_scraped is already loaded with data\n",
    "\n",
    "# Count occurrences of each unique value in 'Name_of_Speaker'\n",
    "name_counts = df_articles['Name_of_Speaker'].value_counts()\n",
    "print(name_counts)\n",
    "\n",
    "\n",
    "# Plotting the counts\n",
    "plt.figure(figsize=(10, 8))  # Set the figure size for better readability\n",
    "name_counts.plot(kind='bar', color='skyblue')  # Create a bar plot\n",
    "plt.title('Count of Each Speaker in Data')  # Title of the plot\n",
    "plt.xlabel('Name of Speaker')  # Label for the x-axis\n",
    "plt.ylabel('Counts')  # Label for the y-axis\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate the x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust subplots to give some padding\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Position column based on the given condition\n",
    "executive_council_members = [\n",
    "    'Christine Lagarde', 'Luis de Guindos', 'Joachim Nagel',\n",
    "    'Isabel Schnabel', 'Philip Lane', 'Piero Cipollone'\n",
    "]\n",
    "\n",
    "df_articles['Position'] = np.where(df_articles['Name_of_Speaker'].isin(executive_council_members), 'Executive Council', 'Governor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the total count of unique values in the \"Position\" column\n",
    "unique_position_counts = df_articles['Position'].value_counts()\n",
    "print(unique_position_counts)\n",
    "\n",
    "# Sum the occurrences of the executive council members in the \"Name_of_Speaker\" column\n",
    "executive_council_count = df_articles['Name_of_Speaker'].isin(executive_council_members).sum()\n",
    "print(\"Count of executive council members in 'Name_of_Speaker':\", executive_council_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging with Monetary Policy Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monetary_policy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'Position' column to df_monetary_policy with \"Monetary Policy Statement\" values\n",
    "df_monetary_policy['Position'] = 'Monetary Policy Statement'\n",
    "print(df_monetary_policy.shape)\n",
    "print(df_articles.shape)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df_combined = pd.concat([df_articles, df_monetary_policy], ignore_index=True)\n",
    "print(df_combined.shape)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('/Users/ruimaciel/Desktop/Barcelona/Master_Thesis/ECB_Perceived_Cacophony/Rui_final_notebooks/df_ready_for_index', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Name_of_Speaker' and calculate the average sentiment\n",
    "grouped_df = df_combined.groupby('Name_of_Speaker')['Sentiment'].mean().reset_index()\n",
    "\n",
    "# Sort the resulting DataFrame by 'Sentiment'\n",
    "grouped_df = grouped_df.sort_values(by='Sentiment')\n",
    "\n",
    "# Print the resulting DataFrame in the desired format\n",
    "for index, row in grouped_df.iterrows():\n",
    "    print(f\"{row['Name_of_Speaker']}, {row['Sentiment']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of -1, 0, and 1 sentiments for each speaker\n",
    "sentiment_counts = df_combined.groupby('Name_of_Speaker')['Sentiment'].apply(lambda x: x.value_counts().reindex([-1, 0, 1], fill_value=0)).unstack()\n",
    "\n",
    "# Calculate the percentages\n",
    "sentiment_percentages = sentiment_counts.div(sentiment_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Add total number of rows per speaker\n",
    "sentiment_counts['Total'] = sentiment_counts.sum(axis=1)\n",
    "\n",
    "# Sort by the 1 sentiment percentage\n",
    "sentiment_percentages_sorted = sentiment_percentages.sort_values(by=1, ascending=False)\n",
    "\n",
    "# Merge the percentages with the total counts\n",
    "sentiment_percentages_sorted['Total'] = sentiment_counts['Total']\n",
    "\n",
    "# Print the sentiment percentages with total counts\n",
    "print(\"\\nSentiment percentages for each speaker sorted by 1 percentage:\")\n",
    "print(sentiment_percentages_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Name_of_Speaker' and calculate the average sentiment\n",
    "grouped_df = df_combined.groupby('Position')['Sentiment'].mean().reset_index()\n",
    "\n",
    "# Sort the resulting DataFrame by 'Sentiment'\n",
    "grouped_df = grouped_df.sort_values(by='Sentiment')\n",
    "\n",
    "# Print the resulting DataFrame in the desired format\n",
    "for index, row in grouped_df.iterrows():\n",
    "    print(f\"{row['Position']}, {row['Sentiment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster\n",
    "\n",
    "for each,number of dovish message per month, number of hawkish per month, drivers of this difference. \n",
    "\n",
    "also add a lag. if i had a lot hawkish messages last do i have more this month.\n",
    "\n",
    "to observe the persistence of the hawkish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster\n",
    "target variable\n",
    "\n",
    "hawkish, \n",
    "\n",
    "dovish\n",
    "\n",
    "difference between the two\n",
    "\n",
    "absolute value the difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
