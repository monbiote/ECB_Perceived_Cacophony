{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.read_excel('Articles_to_Score_Complete.xlsx')\n",
    "\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_scores.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping\n",
    "mapping = {\n",
    "    \"Hawkish\": 1,\n",
    "    \"Neutral\": 0,\n",
    "    \"Dovish\": -1\n",
    "}\n",
    "\n",
    "# Apply the mapping to the relevant columns\n",
    "columns_to_convert = ['Classification Joaquin', 'Classification Rui', 'Classification Ed']\n",
    "for column in columns_to_convert:\n",
    "    df_scores[column] = df_scores[column].map(mapping)\n",
    "\n",
    "# Save the modified DataFrame to a new Excel file if needed\n",
    "df_scores.to_excel('Articles_to_Score_Complete_Converted.xlsx', index=False)\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores['Average_Classification'] = df_scores[columns_to_convert].mean(axis=1)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the results\n",
    "results = {\n",
    "    'Prompt': [],\n",
    "    'Counts_Dovish': [],\n",
    "    'Counts_Neutral': [],\n",
    "    'Counts_Hawkish': [],\n",
    "    'Standard Deviation': [],\n",
    "    'Median': [],\n",
    "    'Average': []\n",
    "}\n",
    "\n",
    "# Calculate the counts, standard deviation, median, and average for each prompt\n",
    "for index, row in df_scores.iterrows():\n",
    "    prompt = row['Manual.summary']\n",
    "    scores = pd.Series([row['Classification Joaquin'], row['Classification Rui'], row['Classification Ed']])\n",
    "    \n",
    "    # Calculate counts for each classification\n",
    "    counts = scores.value_counts().to_dict()\n",
    "    counts_dovish = counts.get(-1, 0)\n",
    "    counts_neutral = counts.get(0, 0)\n",
    "    counts_hawkish = counts.get(1, 0)\n",
    "    \n",
    "    # Calculate standard deviation, median, and average\n",
    "    std_dev = scores.std()\n",
    "    median = scores.median()\n",
    "    average = scores.mean()\n",
    "    \n",
    "    # Store the results\n",
    "    results['Prompt'].append(prompt)\n",
    "    results['Counts_Dovish'].append(counts_dovish)\n",
    "    results['Counts_Neutral'].append(counts_neutral)\n",
    "    results['Counts_Hawkish'].append(counts_hawkish)\n",
    "    results['Standard Deviation'].append(std_dev)\n",
    "    results['Median'].append(median)\n",
    "    results['Average'].append(average)\n",
    "\n",
    "# Create a DataFrame from the results dictionary\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Classification and scoring summary:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the results\n",
    "results = {\n",
    "    'Prompt': [],\n",
    "    'Classification Joaquin': [],\n",
    "    'Classification Rui': [],\n",
    "    'Classification Ed': [],\n",
    "    'Counts_Dovish': [],\n",
    "    'Counts_Neutral': [],\n",
    "    'Counts_Hawkish': [],\n",
    "    'Standard Deviation': [],\n",
    "    'Median': [],\n",
    "    'Average': []\n",
    "}\n",
    "\n",
    "# Calculate the counts, standard deviation, median, and average for each prompt\n",
    "for index, row in df_scores.iterrows():\n",
    "    prompt = row['Manual.summary']\n",
    "    scores = pd.Series([row['Classification Joaquin'], row['Classification Rui'], row['Classification Ed']])\n",
    "    \n",
    "    # Calculate counts for each classification\n",
    "    counts = scores.value_counts().to_dict()\n",
    "    counts_dovish = counts.get(-1, 0)\n",
    "    counts_neutral = counts.get(0, 0)\n",
    "    counts_hawkish = counts.get(1, 0)\n",
    "    \n",
    "    # Calculate standard deviation, median, and average\n",
    "    std_dev = scores.std()\n",
    "    median = scores.median()\n",
    "    average = scores.mean()\n",
    "    \n",
    "    # Store the results\n",
    "    results['Prompt'].append(prompt)\n",
    "    results['Classification Joaquin'].append(row['Classification Joaquin'])\n",
    "    results['Classification Rui'].append(row['Classification Rui'])\n",
    "    results['Classification Ed'].append(row['Classification Ed'])\n",
    "    results['Counts_Dovish'].append(counts_dovish)\n",
    "    results['Counts_Neutral'].append(counts_neutral)\n",
    "    results['Counts_Hawkish'].append(counts_hawkish)\n",
    "    results['Standard Deviation'].append(std_dev)\n",
    "    results['Median'].append(median)\n",
    "    results['Average'].append(average)\n",
    "\n",
    "# Create a DataFrame from the results dictionary\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate overall statistics for each classifier including counts of each classification\n",
    "overall_stats = {\n",
    "    'Classifier': ['Joaquin', 'Rui', 'Ed'],\n",
    "    'Standard Deviation': [\n",
    "        df_scores['Classification Joaquin'].std(),\n",
    "        df_scores['Classification Rui'].std(),\n",
    "        df_scores['Classification Ed'].std()\n",
    "    ],\n",
    "    'Median': [\n",
    "        df_scores['Classification Joaquin'].median(),\n",
    "        df_scores['Classification Rui'].median(),\n",
    "        df_scores['Classification Ed'].median()\n",
    "    ],\n",
    "    'Average': [\n",
    "        df_scores['Classification Joaquin'].mean(),\n",
    "        df_scores['Classification Rui'].mean(),\n",
    "        df_scores['Classification Ed'].mean()\n",
    "    ],\n",
    "    'Counts_Dovish': [\n",
    "        (df_scores['Classification Joaquin'] == -1).sum(),\n",
    "        (df_scores['Classification Rui'] == -1).sum(),\n",
    "        (df_scores['Classification Ed'] == -1).sum()\n",
    "    ],\n",
    "    'Counts_Neutral': [\n",
    "        (df_scores['Classification Joaquin'] == 0).sum(),\n",
    "        (df_scores['Classification Rui'] == 0).sum(),\n",
    "        (df_scores['Classification Ed'] == 0).sum()\n",
    "    ],\n",
    "    'Counts_Hawkish': [\n",
    "        (df_scores['Classification Joaquin'] == 1).sum(),\n",
    "        (df_scores['Classification Rui'] == 1).sum(),\n",
    "        (df_scores['Classification Ed'] == 1).sum()\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the overall statistics dictionary\n",
    "overall_stats_df = pd.DataFrame(overall_stats)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"Classification and scoring summary:\")\n",
    "display(results_df)\n",
    "\n",
    "# Display the overall statistics DataFrame\n",
    "print(\"\\nOverall classifier statistics:\")\n",
    "display(overall_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os  # To access environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add counts of hawkish, neutral, dovish to this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df_scores.to_csv('Random_Articles_to_Score_Complete_Converted.csv', index=False)\n",
    "overall_stats_df.to_csv('Manual_Classifier_Statistics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_scores['Average_Classification'], bins=10, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution of Average Classifications')\n",
    "plt.xlabel('Average Classification')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
